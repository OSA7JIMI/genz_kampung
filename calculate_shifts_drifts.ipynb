{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a02d00d-7b2b-4fca-8a96-53c7ea45e7ac",
   "metadata": {},
   "source": [
    "# This notebook was run for r/SGExams and r/teenagers\n",
    "Change the variable below as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d258bef6-def0-470e-a853-714c2c5cb96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = \"sgexams\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba50280-0935-4a69-bf05-73445f1cfd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8940a655-e856-4358-aa31-f64d257ee6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_activity = pd.read_csv(\"Datasets/Cleaned\"+ sub + \"_posters_activity.csv\")\n",
    "commenter_activity = pd.read_csv(\"Datasets/Cleaned\"+ sub + \"_commenters_activity.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d174ff5-f31c-488e-a926-9c02dfcdefdf",
   "metadata": {},
   "source": [
    "## This will save you from thousands of RuntimeWarning lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575658ad-5f0f-4f5c-bd94-62c3175756e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3168024f-0bc4-40ae-ac3f-a47579c8476b",
   "metadata": {},
   "source": [
    "## Convert the subreddit-topic mapping to a dictionary and assign topics to each row in the Reddit activity datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08582dc2-430e-4c41-9da9-f8a43568d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = subs.set_index('subreddit')['topic'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f3301-2660-422a-89e2-c49a1e65cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_activity['topic'] = poster_activity['subreddit']\n",
    "for key in mapping:\n",
    "    poster_activity['topic'] = poster_activity['topic'].map(mapping)\n",
    "\n",
    "commenter_activity['topic'] = commenter_activity['subreddit']\n",
    "for key in mapping:\n",
    "    commenter_activity['topic'] = commenter_activity['topic'].map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4233792-f883-4431-9c59-fc90a364a281",
   "metadata": {},
   "source": [
    "# Topic shifts and subreddit drifts\n",
    "High level concept from Valensise et al. (2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543a1652-a08b-4893-abcb-09424536a323",
   "metadata": {},
   "source": [
    "## Mathematical algorithm to quantify shifts between topics  \n",
    "Repeat the cell below for commenters by replacing posters_activity with commenter_activity in line 1 and Posters with Commenters in the second last line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9d80e6-cc68-4b69-aa66-507b1f2c3bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, segment in posters_activity.groupby('name'): \n",
    "    segment = segment.sort_values(by='created_utc')\n",
    "    encodings = pd.get_dummies(segment.topic)\n",
    "    result = pd.DataFrame(columns=segment['topic'].unique())\n",
    "    result = result.sort_index(axis=1)\n",
    "\n",
    "    bin_size = 10\n",
    "    x = 0\n",
    "    df_size = len(encodings)\n",
    "\n",
    "    for i in range(1,int(df_size/bin_size)+1):\n",
    "        sum = pd.DataFrame(encodings.iloc[x:i*bin_size].sum()).transpose()\n",
    "        x+=bin_size\n",
    "        result = pd.concat([result,sum],axis=0)\n",
    "        \n",
    "    angles = []\n",
    "    for i in range(len(result)-1):\n",
    "        vector1 = np.array(list(result.iloc[i]))\n",
    "        vector2 = np.array(list(result.iloc[i+1]))\n",
    "\n",
    "        dot_product = np.dot(vector1, vector2)\n",
    "        magnitude1 = np.linalg.norm(vector1)\n",
    "        magnitude2 = np.linalg.norm(vector2)\n",
    "        cosine_similarity = dot_product / (magnitude1 * magnitude2)\n",
    "        \n",
    "        if cosine_similarity> 1:\n",
    "            cosine_similarity = 1\n",
    "        if cosine_similarity<-1:\n",
    "            cosine_similarity = -1\n",
    "        \n",
    "        angle = math.acos(cosine_similarity)\n",
    "        angle = angle*180/math.pi\n",
    "        angles.append(round(angle,2))\n",
    "\n",
    "    angles.append(-1)\n",
    "    result['angle'] = angles\n",
    "\n",
    "    ucsv = sub + '/Posters/Topics/' +name +'.csv'\n",
    "    result.to_csv(ucsv, index  =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6597fe2-278f-4281-818f-f1b533f162cc",
   "metadata": {},
   "source": [
    "## Mathematical algorithm to quantify drifts between subreddits within a topic  \n",
    "Repeat the second cell below for commenters by replacing posters_activity with commenter_activity in line 1 and Posters with Commenters in the fifth last line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18100adc-8241-4609-9184-e1a83430ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(df):\n",
    "    angles = []\n",
    "    for i in range(len(df)-1):\n",
    "        vector1 = np.array(list(df.iloc[i]))\n",
    "        vector2 = np.array(list(df.iloc[i+1]))\n",
    "\n",
    "        dot_product = np.dot(vector1, vector2)\n",
    "        magnitude1 = np.linalg.norm(vector1)\n",
    "        magnitude2 = np.linalg.norm(vector2)\n",
    "        cosine_similarity = dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "        if cosine_similarity> 1:\n",
    "            cosine_similarity = 1\n",
    "        if cosine_similarity<-1:\n",
    "            cosine_similarity = -1\n",
    "\n",
    "        angle = math.acos(cosine_similarity)\n",
    "        angle = angle*180/math.pi\n",
    "        angles.append(round(angle,2))\n",
    "\n",
    "    angles.append(-1)\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d18098c-aa0f-4694-aeb8-0f051c668fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, segment in posters_activity.groupby('name'): \n",
    "    try:\n",
    "        segment = segment.sort_values(by='created_utc')\n",
    "        sub_encode = pd.get_dummies(segment.subreddit)\n",
    "        top_encode = pd.get_dummies(segment.topic)\n",
    "        encodings = pd.concat([sub_encode,top_encode],axis=1)\n",
    "        result = pd.DataFrame(columns=segment['subreddit'].unique())\n",
    "        result = result.sort_index(axis=1)\n",
    "\n",
    "        bin_size = 10\n",
    "        x = 0\n",
    "        df_size = len(encodings)\n",
    "\n",
    "        for i in range(1,int(df_size/bin_size)+1):\n",
    "            sum = pd.DataFrame(encodings.iloc[x:i*bin_size].sum()).transpose()\n",
    "            x+=bin_size\n",
    "            result = pd.concat([result,sum],axis=0)\n",
    "\n",
    "        topics = segment['topic'].unique()\n",
    "\n",
    "        for t in topics: \n",
    "            result[t] = result[t].replace(0.0,np.nan)\n",
    "\n",
    "        for t in topics:\n",
    "            set1 = set(top_dict[t])\n",
    "            set2 = set(segment)\n",
    "            set3 = set1.intersection(set2)\n",
    "            tcol = t + ' SimilarAngle'\n",
    "            result[tcol] = cosine_similarity(result[list(set3)])\n",
    "\n",
    "        filtered_columns = [col for col in result.columns if 'SimilarAngle' in col]\n",
    "        angles_df = pd.DataFrame(result[filtered_columns])\n",
    "        mean_angles = []\n",
    "\n",
    "        for i in range(len(angles_df)):\n",
    "            mean_angles.append(round(np.nanmean(angles_df.iloc[i]),2))\n",
    "        result['Mean Angle'] = mean_angles\n",
    "\n",
    "        ucsv = sub + '/Posters/Subreddits/' +name +'.csv'\n",
    "        result.to_csv(ucsv, index=False)\n",
    "    except:\n",
    "        failed.append(name)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744ec8c1-8456-4d5c-b0a3-89e7d635c10f",
   "metadata": {},
   "source": [
    "# TODO add mathematical reason for failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d45bd5-3f1e-4059-aa10-064fc3239967",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(failed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
